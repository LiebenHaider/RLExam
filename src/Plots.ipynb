{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9c55c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from augment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4664ace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = AugmentationSpace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55b2bc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torch.rand((10, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dcec684",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = [\n",
    "    [  # Sub-policy 1\n",
    "        {'operation': 5, 'magnitude': 3, 'probability': 0.7},  # Cutout at 70%\n",
    "        {'operation': 3, 'magnitude': 2, 'probability': 0.8}   # Shear_x at 80%\n",
    "    ],\n",
    "    [  # Sub-policy 2\n",
    "        {'operation': 1, 'magnitude': 4, 'probability': 0.3},  # Translate_x at 30%\n",
    "        {'operation': 3, 'magnitude': 1, 'probability': 0.9}   # Brightness at 90%\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f5d98d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 32, 32])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_data = apply_auto_augmentations(test_data, policy, space)\n",
    "augmented_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0d4ce8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 32, 32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_data = apply_random_augmentations(test_data, space)\n",
    "augmented_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d6cb0c",
   "metadata": {},
   "source": [
    "## Results of AutoAugment Training a Resnet-18 with a PPO Agent\n",
    "### Objective\n",
    "Three models were trained in parallel (RL-augmented, randomly augmented, no augmentation) to classify images from the CIFAR-10 dataset, choosing one out of ten classes. The goal was to (1) reproduce results using an similar approach and (2) add a baseline comparison - a model trained with random augmentation - to assess whether RL-augmented training truly strengthens generalization.\n",
    "### Description of DAC using RL\n",
    "Dynamic algorithm configuration in essence means optimizing any algorithm (mostly DL) dynamically. Usually, that means optimize specific parameters on-the-fly during training. In this case, tuning the strategy of augmenting images that are fed into a CNN. This could involve cropping, flipping, mirroring or changing contrast. The RL agent should learn a policy during training, which augmentation strategies (the actions) out of a search space (which is the same as the baseline) are optimally so that the learner (the CNN) generalizes well on the validation set. This can be seen as a grey-box optimization problem, because the agent can see the training dynamics (instead of only seeing the result AFTER the learner was trained). Whether or not the computational expense are worth the result can only show in validating with the held-out set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650692f2",
   "metadata": {},
   "source": [
    "## Get files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16ab6ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files do not exist: [Errno 2] No such file or directory: 'src/data/metrics/final_metrics_seednr_42.csv'\n",
      "Files do not exist: [Errno 2] No such file or directory: 'src/data/metrics/final_metrics_seednr_123.csv'\n",
      "Files do not exist: [Errno 2] No such file or directory: 'src/data/metrics/final_metrics_seednr_456.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from main import METRICS_PATH, SEEDS\n",
    "\n",
    "trainingmetrics_list = []\n",
    "testmetrics_list = []\n",
    "agentmetrics = []\n",
    "\n",
    "for seed in SEEDS:\n",
    "    METRICS_FILENAME = f\"final_metrics_seednr_{seed}.csv\"\n",
    "    TESTMETRICS_FILENAME = f\"final_testmetrics_seednr_{seed}.csv\"\n",
    "    AGENTPOLICIES_FILENAME = f\"agent_policies_seednr_{seed}.csv\"\n",
    "    \n",
    "    try:\n",
    "        # Create paths\n",
    "        trainingmetrics_path = os.path.join(METRICS_PATH, METRICS_FILENAME)\n",
    "        testmetrics_path = os.path.join(METRICS_PATH, TESTMETRICS_FILENAME)\n",
    "        agentmetrics_path = os.path.join(METRICS_PATH, AGENTPOLICIES_FILENAME)\n",
    "        \n",
    "        # Get files\n",
    "        trainingmetrics_list.append(pd.read_csv(trainingmetrics_path))\n",
    "        testmetrics_list.append(pd.read_csv(testmetrics_path))\n",
    "        agentmetrics.append(pd.read_csv(agentmetrics_path))\n",
    "    except Exception as e:\n",
    "        print(f\"Files do not exist: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b382c28",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e154ba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all training metrics and add seed info\n",
    "for i, df in enumerate(trainingmetrics_list):\n",
    "    df['seed'] = SEEDS[i]\n",
    "combined_training = pd.concat(trainingmetrics_list, ignore_index=True)\n",
    "\n",
    "# Same for test metrics\n",
    "for i, df in enumerate(testmetrics_list):\n",
    "    df['seed'] = SEEDS[i]\n",
    "combined_test = pd.concat(testmetrics_list, ignore_index=True)\n",
    "\n",
    "# Create plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Training accuracy comparison across methods\n",
    "sns.boxplot(data=combined_test, x='method', y='accuracy', ax=axes[0,0])\n",
    "axes[0,0].set_title('Final Test Accuracy by Method')\n",
    "axes[0,0].set_ylabel('Accuracy')\n",
    "\n",
    "# Plot 2: Training loss over time\n",
    "if 'epoch' in combined_training.columns:\n",
    "    for method in ['rl', 'random', 'none']:\n",
    "        method_data = combined_training[combined_training['method'] == method]\n",
    "        axes[0,1].plot(method_data.groupby('epoch')['loss'].mean(), label=method)\n",
    "    axes[0,1].set_title('Training Loss Over Time')\n",
    "    axes[0,1].legend()\n",
    "\n",
    "# Plot 3: Statistical comparison\n",
    "method_stats = combined_test.groupby('method')['accuracy'].agg(['mean', 'std'])\n",
    "axes[1,0].bar(method_stats.index, method_stats['mean'], yerr=method_stats['std'])\n",
    "axes[1,0].set_title('Mean Accuracy Â± Std')\n",
    "axes[1,0].set_ylabel('Accuracy')\n",
    "\n",
    "# Plot 4: Agent reward trajectory\n",
    "if agentmetrics:\n",
    "    combined_agent = pd.concat(agentmetrics, ignore_index=True)\n",
    "    axes[1,1].plot(combined_agent.groupby('update')['reward'].mean())\n",
    "    axes[1,1].set_title('Agent Reward Over Updates')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Standardenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
